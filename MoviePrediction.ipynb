{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a76c6670-6449-4202-bff9-3d837ede6659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Movie Rating Prediction System\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the path to your movie dataset CSV file (or press Enter to use sample data):  movies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading data: 'utf-8' codec can't decode byte 0xe1 in position 76763: invalid continuation byte\n",
      "Creating a sample dataset for testing...\n",
      "Dataset loaded with 5 rows and 10 columns\n",
      "\n",
      "First 5 records:\n",
      "      Name  Year  Duration              Genre  Rating  Votes    Director  \\\n",
      "0  Movie 1  2020       120             Action     8.5  10000  Director 1   \n",
      "1  Movie 2  2019       105             Comedy     7.2   5000  Director 2   \n",
      "2  Movie 3  2021       135              Drama     8.9  12000  Director 3   \n",
      "3  Movie 4  2018        95  Action, Adventure     6.8   3000  Director 1   \n",
      "4  Movie 5  2022       110    Comedy, Romance     7.5   6000  Director 4   \n",
      "\n",
      "   Actor 1  Actor 2  Actor 3  \n",
      "0  Actor A  Actor E  Actor J  \n",
      "1  Actor B  Actor F  Actor K  \n",
      "2  Actor C  Actor G  Actor L  \n",
      "3  Actor D  Actor H  Actor M  \n",
      "4  Actor B  Actor I  Actor N  \n",
      "\n",
      "Data Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Name      5 non-null      object \n",
      " 1   Year      5 non-null      int64  \n",
      " 2   Duration  5 non-null      int64  \n",
      " 3   Genre     5 non-null      object \n",
      " 4   Rating    5 non-null      float64\n",
      " 5   Votes     5 non-null      int64  \n",
      " 6   Director  5 non-null      object \n",
      " 7   Actor 1   5 non-null      object \n",
      " 8   Actor 2   5 non-null      object \n",
      " 9   Actor 3   5 non-null      object \n",
      "dtypes: float64(1), int64(3), object(6)\n",
      "memory usage: 532.0+ bytes\n",
      "None\n",
      "\n",
      "Statistical Summary:\n",
      "           Name         Year    Duration   Genre   Rating         Votes  \\\n",
      "count         5     5.000000    5.000000       5  5.00000      5.000000   \n",
      "unique        5          NaN         NaN       5      NaN           NaN   \n",
      "top     Movie 1          NaN         NaN  Action      NaN           NaN   \n",
      "freq          1          NaN         NaN       1      NaN           NaN   \n",
      "mean        NaN  2020.000000  113.000000     NaN  7.78000   7200.000000   \n",
      "std         NaN     1.581139   15.247951     NaN  0.88713   3701.351105   \n",
      "min         NaN  2018.000000   95.000000     NaN  6.80000   3000.000000   \n",
      "25%         NaN  2019.000000  105.000000     NaN  7.20000   5000.000000   \n",
      "50%         NaN  2020.000000  110.000000     NaN  7.50000   6000.000000   \n",
      "75%         NaN  2021.000000  120.000000     NaN  8.50000  10000.000000   \n",
      "max         NaN  2022.000000  135.000000     NaN  8.90000  12000.000000   \n",
      "\n",
      "          Director  Actor 1  Actor 2  Actor 3  \n",
      "count            5        5        5        5  \n",
      "unique           4        4        5        5  \n",
      "top     Director 1  Actor B  Actor E  Actor J  \n",
      "freq             2        2        1        1  \n",
      "mean           NaN      NaN      NaN      NaN  \n",
      "std            NaN      NaN      NaN      NaN  \n",
      "min            NaN      NaN      NaN      NaN  \n",
      "25%            NaN      NaN      NaN      NaN  \n",
      "50%            NaN      NaN      NaN      NaN  \n",
      "75%            NaN      NaN      NaN      NaN  \n",
      "max            NaN      NaN      NaN      NaN  \n",
      "\n",
      "Missing Values:\n",
      "Name        0\n",
      "Year        0\n",
      "Duration    0\n",
      "Genre       0\n",
      "Rating      0\n",
      "Votes       0\n",
      "Director    0\n",
      "Actor 1     0\n",
      "Actor 2     0\n",
      "Actor 3     0\n",
      "dtype: int64\n",
      "\n",
      "Data types before conversion:\n",
      "Name         object\n",
      "Year          int64\n",
      "Duration      int64\n",
      "Genre        object\n",
      "Rating      float64\n",
      "Votes         int64\n",
      "Director     object\n",
      "Actor 1      object\n",
      "Actor 2      object\n",
      "Actor 3      object\n",
      "dtype: object\n",
      "\n",
      "Data types after conversion:\n",
      "Name         object\n",
      "Year          int64\n",
      "Duration      int64\n",
      "Genre        object\n",
      "Rating      float64\n",
      "Votes         int64\n",
      "Director     object\n",
      "Actor 1      object\n",
      "Actor 2      object\n",
      "Actor 3      object\n",
      "dtype: object\n",
      "\n",
      "Value ranges for numeric columns:\n",
      "Year: min=2018, max=2022, mean=2020.0\n",
      "Duration: min=95, max=135, mean=113.0\n",
      "Rating: min=6.8, max=8.9, mean=7.780000000000001\n",
      "Votes: min=3000, max=12000, mean=7200.0\n",
      "\n",
      "Target variable 'Rating' stats:\n",
      "Count: 5\n",
      "Min: 6.8\n",
      "Max: 8.9\n",
      "Mean: 7.780000000000001\n",
      "Numerical features: ['Year', 'Duration', 'Votes', 'Decade', 'Director_Avg_Rating', 'Director_Movie_Count', 'Actor_1_Avg_Rating', 'Actor_2_Avg_Rating', 'Actor_3_Avg_Rating', 'Star_Power', 'Genre_Avg_Rating', 'Decade_Avg_Rating', 'Log_Votes']\n",
      "Categorical features: ['Genre', 'Director', 'Actor 1', 'Actor 2', 'Actor 3', 'Primary_Genre', 'Duration_Category']\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Results:\n",
      "  MSE: 0.2510\n",
      "  RMSE: 0.5010\n",
      "  MAE: 0.5010\n",
      "  R-squared: nan\n",
      "\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Results:\n",
      "  MSE: 0.0122\n",
      "  RMSE: 0.1103\n",
      "  MAE: 0.1103\n",
      "  R-squared: nan\n",
      "\n",
      "Training Linear Regression...\n",
      "Linear Regression Results:\n",
      "  MSE: 0.0059\n",
      "  RMSE: 0.0766\n",
      "  MAE: 0.0766\n",
      "  R-squared: nan\n",
      "\n",
      "Best model: Random Forest with R2: nan\n",
      "\n",
      "Feature Importance:\n",
      "                     Feature  Importance\n",
      "36  Duration_Category_Medium    0.109473\n",
      "6         Actor_1_Avg_Rating    0.078567\n",
      "23           Actor 1_Actor D    0.055260\n",
      "14   Genre_Action, Adventure    0.050799\n",
      "7         Actor_2_Avg_Rating    0.047119\n",
      "8         Actor_3_Avg_Rating    0.046692\n",
      "9                 Star_Power    0.043921\n",
      "20           Actor 1_Actor A    0.038143\n",
      "1                   Duration    0.036883\n",
      "34       Primary_Genre_Drama    0.036520\n",
      "3                     Decade    0.033174\n",
      "12                 Log_Votes    0.031703\n",
      "26           Actor 2_Actor H    0.031525\n",
      "0                       Year    0.029547\n",
      "15     Genre_Comedy, Romance    0.029058\n",
      "25           Actor 2_Actor G    0.027291\n",
      "19       Director_Director 4    0.024475\n",
      "10          Genre_Avg_Rating    0.023729\n",
      "4        Director_Avg_Rating    0.022740\n",
      "24           Actor 2_Actor E    0.022410\n",
      "\n",
      "Performing hyperparameter tuning for Random Forest...\n",
      "Best parameters: {'model__max_depth': None, 'model__min_samples_split': 2, 'model__n_estimators': 50}\n",
      "Best CV score: 0.6652 (MSE)\n",
      "\n",
      "Tuned Model Performance:\n",
      "  RMSE: 0.5140\n",
      "  R-squared: nan\n",
      "Model saved successfully to movie_rating_model.pkl\n",
      "\n",
      "Starting interactive rating estimator...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#  Data Loading and Exploration\n",
    "def load_and_explore_data(file_path):\n",
    "    \"\"\"\n",
    "    Load the dataset and perform initial exploration\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv('Downloads/movies.csv')\n",
    "        print(f\"Dataset loaded successfully from {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        print(\"Creating a sample dataset for testing...\")\n",
    "        \n",
    "        # Create a small sample dataset for testing\n",
    "        data = {\n",
    "            'Name': ['Movie 1', 'Movie 2', 'Movie 3', 'Movie 4', 'Movie 5'],\n",
    "            'Year': [2020, 2019, 2021, 2018, 2022],\n",
    "            'Duration': [120, 105, 135, 95, 110],\n",
    "            'Genre': ['Action', 'Comedy', 'Drama', 'Action, Adventure', 'Comedy, Romance'],\n",
    "            'Rating': [8.5, 7.2, 8.9, 6.8, 7.5],\n",
    "            'Votes': [10000, 5000, 12000, 3000, 6000],\n",
    "            'Director': ['Director 1', 'Director 2', 'Director 3', 'Director 1', 'Director 4'],\n",
    "            'Actor 1': ['Actor A', 'Actor B', 'Actor C', 'Actor D', 'Actor B'],\n",
    "            'Actor 2': ['Actor E', 'Actor F', 'Actor G', 'Actor H', 'Actor I'],\n",
    "            'Actor 3': ['Actor J', 'Actor K', 'Actor L', 'Actor M', 'Actor N']\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "    \n",
    "    print(f\"Dataset loaded with {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "    print(\"\\nFirst 5 records:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    print(\"\\nData Information:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(\"\\nStatistical Summary:\")\n",
    "    print(df.describe(include='all'))\n",
    "    \n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    return df\n",
    "\n",
    "#  Data Preprocessing\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the data including handling missing values and encoding categorical variables\n",
    "    \"\"\"\n",
    "    processed_df = df.copy()\n",
    "    \n",
    "    # Print data types before conversion\n",
    "    print(\"\\nData types before conversion:\")\n",
    "    print(processed_df.dtypes)\n",
    "    \n",
    "    #  Convert Year to numeric, forcing non-numeric values to NaN\n",
    "    if 'Year' in processed_df.columns:\n",
    "        processed_df['Year'] = pd.to_numeric(processed_df['Year'], errors='coerce')\n",
    "    \n",
    "    #  Convert Duration to numeric\n",
    "    if 'Duration' in processed_df.columns:\n",
    "        if processed_df['Duration'].dtype == 'object':\n",
    "            # Extract numeric values from duration strings (e.g., \"109 min\" -> 109)\n",
    "            processed_df['Duration'] = processed_df['Duration'].str.extract(r'(\\d+)').astype(float)\n",
    "        else:\n",
    "            processed_df['Duration'] = pd.to_numeric(processed_df['Duration'], errors='coerce')\n",
    "    \n",
    "    #  Convert Rating to numeric\n",
    "    if 'Rating' in processed_df.columns:\n",
    "        processed_df['Rating'] = pd.to_numeric(processed_df['Rating'], errors='coerce')\n",
    "    \n",
    "    #  Convert Votes to numeric\n",
    "    if 'Votes' in processed_df.columns:\n",
    "        processed_df['Votes'] = pd.to_numeric(processed_df['Votes'], errors='coerce')\n",
    "    \n",
    "    # Print data types after conversion\n",
    "    print(\"\\nData types after conversion:\")\n",
    "    print(processed_df.dtypes)\n",
    "    \n",
    "    # Print value ranges to check for outliers\n",
    "    print(\"\\nValue ranges for numeric columns:\")\n",
    "    for col in ['Year', 'Duration', 'Rating', 'Votes']:\n",
    "        if col in processed_df.columns:\n",
    "            print(f\"{col}: min={processed_df[col].min()}, max={processed_df[col].max()}, mean={processed_df[col].mean()}\")\n",
    "    \n",
    "    #  Handle missing values\n",
    "    # For numerical columns\n",
    "    num_cols = ['Year', 'Duration', 'Rating', 'Votes']\n",
    "    for col in num_cols:\n",
    "        if col in processed_df.columns:\n",
    "            # Fill with median\n",
    "            median_val = processed_df[col].median()\n",
    "            processed_df[col] = processed_df[col].fillna(median_val)\n",
    "    \n",
    "    # For categorical columns\n",
    "    cat_cols = ['Name', 'Genre', 'Director', 'Actor 1', 'Actor 2', 'Actor 3']\n",
    "    for col in cat_cols:\n",
    "        if col in processed_df.columns:\n",
    "            # Fill with \"Unknown\"\n",
    "            processed_df[col] = processed_df[col].fillna(\"Unknown\")\n",
    "    \n",
    "    #  Process Genre column (might contain multiple genres)\n",
    "    if 'Genre' in processed_df.columns:\n",
    "        # Extract primary genre if multiple genres are present\n",
    "        processed_df['Primary_Genre'] = processed_df['Genre'].apply(\n",
    "            lambda x: x.split(',')[0].strip() if isinstance(x, str) else \"Unknown\"\n",
    "        )\n",
    "    \n",
    "    return processed_df\n",
    "\n",
    "#  Feature Engineering\n",
    "def engineer_features(df):\n",
    "    \"\"\"\n",
    "    Create new features that might help prediction performance\n",
    "    \"\"\"\n",
    "    featured_df = df.copy()\n",
    "    \n",
    "    #  Extract decade from year\n",
    "    if 'Year' in featured_df.columns:\n",
    "        featured_df['Decade'] = (featured_df['Year'] // 10) * 10\n",
    "    \n",
    "    #  Calculate director success metrics\n",
    "    if 'Director' in featured_df.columns and 'Rating' in featured_df.columns:\n",
    "        # Average rating by director\n",
    "        director_avg = featured_df.groupby('Director')['Rating'].mean().reset_index()\n",
    "        director_avg.columns = ['Director', 'Director_Avg_Rating']\n",
    "        \n",
    "        # Number of movies by director\n",
    "        director_count = featured_df.groupby('Director').size().reset_index()\n",
    "        director_count.columns = ['Director', 'Director_Movie_Count']\n",
    "        \n",
    "        # Merge these features back\n",
    "        featured_df = pd.merge(featured_df, director_avg, on='Director', how='left')\n",
    "        featured_df = pd.merge(featured_df, director_count, on='Director', how='left')\n",
    "    \n",
    "    #  Calculate actor success metrics\n",
    "    for actor_col in ['Actor 1', 'Actor 2', 'Actor 3']:\n",
    "        if actor_col in featured_df.columns and 'Rating' in featured_df.columns:\n",
    "            # Average rating by actor\n",
    "            actor_avg = featured_df.groupby(actor_col)['Rating'].mean().reset_index()\n",
    "            actor_avg.columns = [actor_col, f'{actor_col.replace(\" \", \"_\")}_Avg_Rating']\n",
    "            \n",
    "            # Merge back\n",
    "            featured_df = pd.merge(featured_df, actor_avg, on=actor_col, how='left')\n",
    "    \n",
    "    #  Create a \"Star Power\" feature - average of the three actors' average ratings\n",
    "    actor_rating_cols = []\n",
    "    for actor in ['Actor 1', 'Actor 2', 'Actor 3']:\n",
    "        rating_col = f'{actor.replace(\" \", \"_\")}_Avg_Rating'\n",
    "        if rating_col in featured_df.columns:\n",
    "            actor_rating_cols.append(rating_col)\n",
    "    \n",
    "    if actor_rating_cols:\n",
    "        featured_df['Star_Power'] = featured_df[actor_rating_cols].mean(axis=1)\n",
    "    \n",
    "    #  Calculate average rating by genre\n",
    "    if 'Primary_Genre' in featured_df.columns and 'Rating' in featured_df.columns:\n",
    "        genre_avg = featured_df.groupby('Primary_Genre')['Rating'].mean().reset_index()\n",
    "        genre_avg.columns = ['Primary_Genre', 'Genre_Avg_Rating']\n",
    "        featured_df = pd.merge(featured_df, genre_avg, on='Primary_Genre', how='left')\n",
    "    \n",
    "    #  Calculate average rating by decade\n",
    "    if 'Decade' in featured_df.columns and 'Rating' in featured_df.columns:\n",
    "        decade_avg = featured_df.groupby('Decade')['Rating'].mean().reset_index()\n",
    "        decade_avg.columns = ['Decade', 'Decade_Avg_Rating']\n",
    "        featured_df = pd.merge(featured_df, decade_avg, on='Decade', how='left')\n",
    "    \n",
    "    #  Calculate log transform of votes to handle skewness\n",
    "    if 'Votes' in featured_df.columns:\n",
    "        featured_df['Log_Votes'] = np.log1p(featured_df['Votes'])\n",
    "    \n",
    "    #  Duration categories\n",
    "    if 'Duration' in featured_df.columns:\n",
    "        bins = [0, 90, 120, 150, 1000]\n",
    "        labels = ['Short', 'Medium', 'Long', 'Very Long']\n",
    "        featured_df['Duration_Category'] = pd.cut(featured_df['Duration'], bins=bins, labels=labels, right=False)\n",
    "    \n",
    "    return featured_df\n",
    "\n",
    "# Prepare data for modeling\n",
    "def prepare_for_modeling(df, target_col='Rating'):\n",
    "    \"\"\"\n",
    "    Prepare the data for modeling by splitting into features and target\n",
    "    and handling categorical variables\n",
    "    \"\"\"\n",
    "    # Identify features to keep, excluding the original target\n",
    "    feature_df = df.copy()\n",
    "    \n",
    "    # Check if target exists and has valid data\n",
    "    if target_col not in feature_df.columns:\n",
    "        raise ValueError(f\"Target column '{target_col}' not found in dataframe\")\n",
    "    \n",
    "    # Check target variable range and stats\n",
    "    print(f\"\\nTarget variable '{target_col}' stats:\")\n",
    "    print(f\"Count: {feature_df[target_col].count()}\")\n",
    "    print(f\"Min: {feature_df[target_col].min()}\")\n",
    "    print(f\"Max: {feature_df[target_col].max()}\")\n",
    "    print(f\"Mean: {feature_df[target_col].mean()}\")\n",
    "    \n",
    "    # Exclude the target and any redundant columns\n",
    "    columns_to_drop = [target_col, 'Name']  # Add other columns that shouldn't be used for prediction\n",
    "    \n",
    "    # Only drop columns that exist\n",
    "    cols_to_drop = [col for col in columns_to_drop if col in feature_df.columns]\n",
    "    \n",
    "    # Features and target\n",
    "    X = feature_df.drop(cols_to_drop, axis=1)\n",
    "    y = feature_df[target_col]\n",
    "    \n",
    "    # Identify numerical and categorical columns\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    print(f\"Numerical features: {numerical_cols}\")\n",
    "    print(f\"Categorical features: {categorical_cols}\")\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, numerical_cols, categorical_cols\n",
    "\n",
    "#  Build and evaluate the model\n",
    "def build_and_evaluate_model(X_train, X_test, y_train, y_test, numerical_cols, categorical_cols):\n",
    "    \"\"\"\n",
    "    Build, train and evaluate the prediction model\n",
    "    \"\"\"\n",
    "    # Create preprocessor\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "    \n",
    "    # Combine transformers in a column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Create and evaluate different models\n",
    "    models = {\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "        'Linear Regression': LinearRegression()\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        # Create a pipeline with preprocessing and model\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        # Fit the model\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        # Evaluate\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        results[name] = {\n",
    "            'MSE': mse,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'R2': r2,\n",
    "            'Pipeline': pipeline\n",
    "        }\n",
    "        \n",
    "        print(f\"{name} Results:\")\n",
    "        print(f\"  MSE: {mse:.4f}\")\n",
    "        print(f\"  RMSE: {rmse:.4f}\")\n",
    "        print(f\"  MAE: {mae:.4f}\")\n",
    "        print(f\"  R-squared: {r2:.4f}\")\n",
    "    \n",
    "    # Find the best model\n",
    "    best_model_name = max(results, key=lambda k: results[k]['R2'])\n",
    "    best_model = results[best_model_name]['Pipeline']\n",
    "    \n",
    "    print(f\"\\nBest model: {best_model_name} with R2: {results[best_model_name]['R2']:.4f}\")\n",
    "    \n",
    "    return best_model, results\n",
    "\n",
    "#  Feature Importance Analysis\n",
    "def analyze_feature_importance(model, numerical_cols, categorical_cols):\n",
    "    \"\"\"\n",
    "    Analyze and visualize feature importance from the best model\n",
    "    \"\"\"\n",
    "    # Check if the model has feature_importances_ attribute (tree-based models)\n",
    "    if hasattr(model[-1], 'feature_importances_'):\n",
    "        try:\n",
    "            # Get feature names after preprocessing\n",
    "            preprocessor = model[0]\n",
    "            \n",
    "            # Get transformed feature names\n",
    "            transformed_numerical = numerical_cols\n",
    "            \n",
    "            # For categorical features, get all the one-hot encoded column names\n",
    "            ohe = preprocessor.transformers_[1][1].named_steps['onehot']\n",
    "            transformed_categorical = ohe.get_feature_names_out(categorical_cols).tolist()\n",
    "            \n",
    "            all_features = transformed_numerical + transformed_categorical\n",
    "            \n",
    "            # Get feature importances\n",
    "            importances = model[-1].feature_importances_\n",
    "            \n",
    "            # Ensure lengths match\n",
    "            if len(all_features) == len(importances):\n",
    "                # Create a DataFrame for better visualization\n",
    "                feature_importance = pd.DataFrame({\n",
    "                    'Feature': all_features,\n",
    "                    'Importance': importances\n",
    "                }).sort_values('Importance', ascending=False)\n",
    "                \n",
    "                print(\"\\nFeature Importance:\")\n",
    "                print(feature_importance.head(20))  # Show top 20 features\n",
    "                \n",
    "                # Plot\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.barplot(x='Importance', y='Feature', data=feature_importance.head(15))\n",
    "                plt.title('Top 15 Feature Importances')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig('feature_importance.png')\n",
    "                plt.close()\n",
    "                \n",
    "                return feature_importance\n",
    "            else:\n",
    "                print(f\"Feature length mismatch: {len(all_features)} features vs {len(importances)} importances\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing feature importance: {str(e)}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"Model doesn't have feature_importances_ attribute\")\n",
    "        return None\n",
    "\n",
    "#  Hyperparameter Tuning\n",
    "def tune_best_model(X_train, y_train, best_model_name, numerical_cols, categorical_cols):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter tuning on the best model\n",
    "    \"\"\"\n",
    "    # Create the preprocessor\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Define the parameter grid based on the best model\n",
    "    if best_model_name == 'Random Forest':\n",
    "        model = RandomForestRegressor(random_state=42)\n",
    "        param_grid = {\n",
    "            'model__n_estimators': [50, 100],\n",
    "            'model__max_depth': [None, 20],\n",
    "            'model__min_samples_split': [2, 5]\n",
    "        }\n",
    "    elif best_model_name == 'Gradient Boosting':\n",
    "        model = GradientBoostingRegressor(random_state=42)\n",
    "        param_grid = {\n",
    "            'model__n_estimators': [50, 100],\n",
    "            'model__learning_rate': [0.01, 0.1],\n",
    "            'model__max_depth': [3, 5]\n",
    "        }\n",
    "    else:  # Linear Regression - not much to tune\n",
    "        model = LinearRegression()\n",
    "        param_grid = {}\n",
    "    \n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Skip grid search tuning if Linear Regression but still fit the model\n",
    "    if best_model_name == 'Linear Regression':\n",
    "        print(\"Linear Regression doesn't require hyperparameter tuning\")\n",
    "        pipeline.fit(X_train, y_train)  # Make sure to fit the model\n",
    "        return pipeline\n",
    "    \n",
    "    # Perform grid search\n",
    "    print(f\"\\nPerforming hyperparameter tuning for {best_model_name}...\")\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, \n",
    "        param_grid, \n",
    "        cv=3,  # Reduced from 5 for speed\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1  # Use all available cores\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV score: {-grid_search.best_score_:.4f} (MSE)\")\n",
    "    \n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "#  Estimate movie rating\n",
    "def estimate_movie_rating(model, featured_df, new_movie_info):\n",
    "    \"\"\"\n",
    "    Estimate a movie rating based on movie information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a DataFrame with a single row for the new movie\n",
    "        new_movie_df = pd.DataFrame([new_movie_info])\n",
    "        \n",
    "        # Process the new movie data\n",
    "        processed_df = new_movie_df.copy()\n",
    "        \n",
    "        # Add all columns from featured_df that are missing in processed_df\n",
    "        for col in featured_df.columns:\n",
    "            if col not in processed_df.columns:\n",
    "                # Add with appropriate default value based on data type\n",
    "                if col in ['Year', 'Duration', 'Votes']:\n",
    "                    processed_df[col] = featured_df[col].median()\n",
    "                else:\n",
    "                    if featured_df[col].dtype.name == 'category':\n",
    "                        processed_df[col] = featured_df[col].mode().iloc[0] if not featured_df[col].mode().empty else \"Unknown\"\n",
    "                    elif pd.api.types.is_numeric_dtype(featured_df[col]):\n",
    "                        processed_df[col] = featured_df[col].median()\n",
    "                    else:\n",
    "                        processed_df[col] = featured_df[col].mode().iloc[0] if not featured_df[col].mode().empty else \"Unknown\"\n",
    "        \n",
    "        # Feature engineering for the new movie\n",
    "        # Extract primary genre\n",
    "        if 'Genre' in processed_df.columns and 'Primary_Genre' not in processed_df.columns:\n",
    "            processed_df['Primary_Genre'] = processed_df['Genre'].apply(\n",
    "                lambda x: x.split(',')[0].strip() if isinstance(x, str) else \"Unknown\"\n",
    "            )\n",
    "        \n",
    "        # Add decade from year\n",
    "        if 'Year' in processed_df.columns and 'Decade' not in processed_df.columns:\n",
    "            processed_df['Decade'] = (processed_df['Year'] // 10) * 10\n",
    "        \n",
    "        # Add Log_Votes\n",
    "        if 'Votes' in processed_df.columns and 'Log_Votes' not in processed_df.columns:\n",
    "            processed_df['Log_Votes'] = np.log1p(processed_df['Votes'])\n",
    "        \n",
    "        # Calculate duration category\n",
    "        if 'Duration' in processed_df.columns and 'Duration_Category' not in processed_df.columns:\n",
    "            bins = [0, 90, 120, 150, 1000]\n",
    "            labels = ['Short', 'Medium', 'Long', 'Very Long']\n",
    "            processed_df['Duration_Category'] = pd.cut(processed_df['Duration'], bins=bins, labels=labels, right=False)\n",
    "        \n",
    "        # If there are features that the model expects but we don't have, we need to drop them\n",
    "        if 'Rating' in processed_df.columns:\n",
    "            processed_df = processed_df.drop('Rating', axis=1)\n",
    "        \n",
    "        if 'Name' in processed_df.columns:\n",
    "            processed_df = processed_df.drop('Name', axis=1)\n",
    "        \n",
    "        # Make the prediction\n",
    "        prediction = model.predict(processed_df)\n",
    "        \n",
    "        return round(prediction[0], 1)  # Round to 1 decimal place\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error estimating rating: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "#  Create interactive GUI interface\n",
    "def create_interactive_rating_estimator(model, featured_df):\n",
    "    \"\"\"\n",
    "    Creates an interactive interface for estimating movie ratings\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import tkinter as tk\n",
    "        from tkinter import ttk, messagebox\n",
    "    except ImportError:\n",
    "        print(\"Tkinter not available. Using console interface instead.\")\n",
    "        return demonstrate_rating_estimator(model, featured_df)\n",
    "    \n",
    "    # Create the main window\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Movie Rating Estimator\")\n",
    "    root.geometry(\"600x500\")\n",
    "    root.configure(padx=20, pady=20)\n",
    "    \n",
    "    # Create style\n",
    "    style = ttk.Style()\n",
    "    style.configure(\"TLabel\", font=(\"Arial\", 11))\n",
    "    style.configure(\"TButton\", font=(\"Arial\", 11))\n",
    "    style.configure(\"TEntry\", font=(\"Arial\", 11))\n",
    "    \n",
    "    # Create a frame\n",
    "    frame = ttk.Frame(root, padding=10)\n",
    "    frame.pack(fill=\"both\", expand=True)\n",
    "    \n",
    "    # Create variables to store input\n",
    "    movie_name = tk.StringVar()\n",
    "    movie_year = tk.StringVar()\n",
    "    movie_duration = tk.StringVar()\n",
    "    movie_genre = tk.StringVar()\n",
    "    movie_director = tk.StringVar()\n",
    "    movie_actor1 = tk.StringVar()\n",
    "    movie_actor2 = tk.StringVar()\n",
    "    movie_actor3 = tk.StringVar()\n",
    "    \n",
    "    # Create input fields\n",
    "    ttk.Label(frame, text=\"Movie Title:\").grid(column=0, row=0, sticky=\"w\", pady=5)\n",
    "    ttk.Entry(frame, width=40, textvariable=movie_name).grid(column=1, row=0, pady=5)\n",
    "    \n",
    "    ttk.Label(frame, text=\"Release Year:\").grid(column=0, row=1, sticky=\"w\", pady=5)\n",
    "    ttk.Entry(frame, width=40, textvariable=movie_year).grid(column=1, row=1, pady=5)\n",
    "    \n",
    "    ttk.Label(frame, text=\"Duration (minutes):\").grid(column=0, row=2, sticky=\"w\", pady=5)\n",
    "    ttk.Entry(frame, width=40, textvariable=movie_duration).grid(column=1, row=2, pady=5)\n",
    "    \n",
    "    ttk.Label(frame, text=\"Genre(s) (comma separated):\").grid(column=0, row=3, sticky=\"w\", pady=5)\n",
    "    ttk.Entry(frame, width=40, textvariable=movie_genre).grid(column=1, row=3, pady=5)\n",
    "    \n",
    "    ttk.Label(frame, text=\"Director:\").grid(column=0, row=4, sticky=\"w\", pady=5)\n",
    "    ttk.Entry(frame, width=40, textvariable=movie_director).grid(column=1, row=4, pady=5)\n",
    "    \n",
    "    ttk.Label(frame, text=\"Lead Actor/Actress:\").grid(column=0, row=5, sticky=\"w\", pady=5)\n",
    "    ttk.Entry(frame, width=40, textvariable=movie_actor1).grid(column=1, row=5, pady=5)\n",
    "    \n",
    "    ttk.Label(frame, text=\"Supporting Actor/Actress 1:\").grid(column=0, row=6, sticky=\"w\", pady=5)\n",
    "    ttk.Entry(frame, width=40, textvariable=movie_actor2).grid(column=1, row=6, pady=5)\n",
    "    \n",
    "    ttk.Label(frame, text=\"Supporting Actor/Actress 2:\").grid(column=0, row=7, sticky=\"w\", pady=5)\n",
    "    ttk.Entry(frame, width=40, textvariable=movie_actor3).grid(column=1, row=7, pady=5)\n",
    "    \n",
    "    # Create result labels\n",
    "    result_frame = ttk.Frame(frame, padding=(0, 10, 0, 0))\n",
    "    result_frame.grid(column=0, row=9, columnspan=2, sticky=\"ew\")\n",
    "    \n",
    "    rating_label = ttk.Label(result_frame, text=\"\", font=(\"Arial\", 12, \"bold\"))\n",
    "    rating_label.pack(pady=5)\n",
    "    \n",
    "    interpretation_label = ttk.Label(result_frame, text=\"\")\n",
    "    interpretation_label.pack(pady=5)\n",
    "    \n",
    "    # Define the predict function\n",
    "    def predict_rating():\n",
    "        try:\n",
    "            # Validate inputs\n",
    "            name = movie_name.get().strip()\n",
    "            if not name:\n",
    "                messagebox.showerror(\"Error\", \"Please enter a movie title\")\n",
    "                return\n",
    "            \n",
    "            try:\n",
    "                year = int(movie_year.get().strip())\n",
    "                if not (1900 <= year <= 2030):\n",
    "                    messagebox.showerror(\"Error\", \"Year must be between 1900 and 2030\")\n",
    "                    return\n",
    "            except ValueError:\n",
    "                messagebox.showerror(\"Error\", \"Year must be a valid number\")\n",
    "                return\n",
    "            \n",
    "            try:\n",
    "                duration = int(movie_duration.get().strip())\n",
    "                if not (30 <= duration <= 300):\n",
    "                    messagebox.showerror(\"Error\", \"Duration must be between 30 and 300 minutes\")\n",
    "                    return\n",
    "            except ValueError:\n",
    "                messagebox.showerror(\"Error\", \"Duration must be a valid number\")\n",
    "                return\n",
    "            \n",
    "            genre = movie_genre.get().strip()\n",
    "            if not genre:\n",
    "                messagebox.showerror(\"Error\", \"Please enter at least one genre\")\n",
    "                return\n",
    "            \n",
    "            director = movie_director.get().strip() or \"Unknown\"\n",
    "            actor1 = movie_actor1.get().strip() or \"Unknown\"\n",
    "            actor2 = movie_actor2.get().strip() or \"Unknown\"\n",
    "            actor3 = movie_actor3.get().strip() or \"Unknown\"\n",
    "            \n",
    "            # Create movie info dictionary\n",
    "            movie_info = {\n",
    "                'Name': name,\n",
    "                'Year': year,\n",
    "                'Duration': duration,\n",
    "                'Genre': genre,\n",
    "                'Director': director,\n",
    "                'Actor 1': actor1,\n",
    "                'Actor 2': actor2,\n",
    "                'Actor 3': actor3,\n",
    "                'Votes': 5000  # Default value\n",
    "            }\n",
    "            \n",
    "            # Make prediction\n",
    "            predicted_rating = estimate_movie_rating(model, featured_df, movie_info)\n",
    "            \n",
    "            if predicted_rating is not None:\n",
    "                # Update the rating label\n",
    "                rating_label.config(text=f\"Predicted Rating: {predicted_rating}/10\")\n",
    "                \n",
    "                # Update interpretation\n",
    "                if predicted_rating >= 8.0:\n",
    "                    interpretation = \"This movie is predicted to be excellent!\"\n",
    "                elif predicted_rating >= 7.0:\n",
    "                    interpretation = \"This movie is predicted to be very good.\"\n",
    "                elif predicted_rating >= 6.0:\n",
    "                    interpretation = \"This movie is predicted to be above average.\"\n",
    "                elif predicted_rating >= 5.0:\n",
    "                    interpretation = \"This movie is predicted to be average.\"\n",
    "                else:\n",
    "                    interpretation = \"This movie is predicted to be below average.\"\n",
    "                \n",
    "                interpretation_label.config(text=interpretation)\n",
    "            else:\n",
    "                rating_label.config(text=\"Unable to predict rating\")\n",
    "                interpretation_label.config(text=\"Please check console for debug information\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"An error occurred: {str(e)}\")\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    # Create predict button\n",
    "    predict_button = ttk.Button(frame, text=\"Predict Rating\", command=predict_rating)\n",
    "    predict_button.grid(column=0, row=8, columnspan=2, pady=15)\n",
    "    \n",
    "    # Create reset button\n",
    "    def reset_form():\n",
    "        movie_name.set(\"\")\n",
    "        movie_year.set(\"\")\n",
    "        movie_duration.set(\"\")\n",
    "        movie_genre.set(\"\")\n",
    "        movie_director.set(\"\")\n",
    "        movie_actor1.set(\"\")\n",
    "        movie_actor2.set(\"\")\n",
    "        movie_actor3.set(\"\")\n",
    "        rating_label.config(text=\"\")\n",
    "        interpretation_label.config(text=\"\")\n",
    "    \n",
    "    reset_button = ttk.Button(frame, text=\"Reset\", command=reset_form)\n",
    "    reset_button.grid(column=0, row=10, columnspan=2, pady=5)\n",
    "    \n",
    "    # Create a sample movie button\n",
    "    def load_sample():\n",
    "        movie_name.set(\"The Awesome Adventure\")\n",
    "        movie_year.set(\"2024\")\n",
    "        movie_duration.set(\"142\")\n",
    "        movie_genre.set(\"Action, Adventure\")\n",
    "        movie_director.set(\"Steven Spielberg\")\n",
    "        movie_actor1.set(\"Tom Hanks\")\n",
    "        movie_actor2.set(\"Emma Stone\")\n",
    "        movie_actor3.set(\"Denzel Washington\")\n",
    "    \n",
    "    sample_button = ttk.Button(frame, text=\"Load Sample Movie\", command=load_sample)\n",
    "    sample_button.grid(column=0, row=11, columnspan=2, pady=5)\n",
    "    \n",
    "    # Start the GUI\n",
    "    root.mainloop()\n",
    "\n",
    "#  Console demo\n",
    "def demonstrate_rating_estimator(model, featured_df):\n",
    "    \"\"\"\n",
    "    Console-based demonstration of the rating estimator\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Movie Rating Estimator ===\")\n",
    "    print(\"Enter information about a movie to predict its rating\")\n",
    "    \n",
    "    try:\n",
    "        # Input movie information\n",
    "        name = input(\"Movie Title: \")\n",
    "        \n",
    "        year = None\n",
    "        while year is None:\n",
    "            try:\n",
    "                year = int(input(\"Release Year: \"))\n",
    "                if not (1900 <= year <= 2030):\n",
    "                    print(\"Year must be between 1900 and 2030\")\n",
    "                    year = None\n",
    "            except ValueError:\n",
    "                print(\"Please enter a valid year as a number\")\n",
    "        \n",
    "        duration = None\n",
    "        while duration is None:\n",
    "            try:\n",
    "                duration = int(input(\"Duration (minutes): \"))\n",
    "                if not (30 <= duration <= 300):\n",
    "                    print(\"Duration must be between 30 and 300 minutes\")\n",
    "                    duration = None\n",
    "            except ValueError:\n",
    "                print(\"Please enter a valid duration as a number\")\n",
    "        \n",
    "        genre = input(\"Genre(s) (comma separated): \")\n",
    "        director = input(\"Director: \") or \"Unknown\"\n",
    "        actor1 = input(\"Lead Actor/Actress: \") or \"Unknown\"\n",
    "        actor2 = input(\"Supporting Actor/Actress 1: \") or \"Unknown\"\n",
    "        actor3 = input(\"Supporting Actor/Actress 2: \") or \"Unknown\"\n",
    "        \n",
    "        # Create movie info dictionary\n",
    "        movie_info = {\n",
    "            'Name': name,\n",
    "            'Year': year,\n",
    "            'Duration': duration,\n",
    "            'Genre': genre,\n",
    "            'Director': director,\n",
    "            'Actor 1': actor1,\n",
    "            'Actor 2': actor2,\n",
    "            'Actor 3': actor3,\n",
    "            'Votes': 5000  # Default value\n",
    "        }\n",
    "        \n",
    "        # Make prediction\n",
    "        predicted_rating = estimate_movie_rating(model, featured_df, movie_info)\n",
    "        \n",
    "        if predicted_rating is not None:\n",
    "            print(f\"\\nPredicted Rating: {predicted_rating}/10\")\n",
    "            \n",
    "            # Add interpretation\n",
    "            if predicted_rating >= 8.0:\n",
    "                interpretation = \"This movie is predicted to be excellent!\"\n",
    "            elif predicted_rating >= 7.0:\n",
    "                interpretation = \"This movie is predicted to be very good.\"\n",
    "            elif predicted_rating >= 6.0:\n",
    "                interpretation = \"This movie is predicted to be above average.\"\n",
    "            elif predicted_rating >= 5.0:\n",
    "                interpretation = \"This movie is predicted to be average.\"\n",
    "            else:\n",
    "                interpretation = \"This movie is predicted to be below average.\"\n",
    "            \n",
    "            print(interpretation)\n",
    "        else:\n",
    "            print(\"Unable to predict rating. Please check console for debug information.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    print(\"\\nThanks for using the Movie Rating Estimator!\")\n",
    "\n",
    "#  Visualize the predictions\n",
    "def visualize_predictions(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Create visualizations of the model's predictions\n",
    "    \"\"\"\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Create a dataframe with actual and predicted values\n",
    "    results_df = pd.DataFrame({\n",
    "        'Actual': y_test,\n",
    "        'Predicted': y_pred,\n",
    "        'Error': y_test - y_pred\n",
    "    })\n",
    "    \n",
    "    # 1. Actual vs Predicted scatterplot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "    \n",
    "    # Add perfect prediction line\n",
    "    min_val = min(min(y_test), min(y_pred))\n",
    "    max_val = max(max(y_test), max(y_pred))\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "    \n",
    "    plt.xlabel('Actual Rating')\n",
    "    plt.ylabel('Predicted Rating')\n",
    "    plt.title('Actual vs Predicted Ratings')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('actual_vs_predicted.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Error distribution histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(results_df['Error'], bins=20, alpha=0.7, color='blue', edgecolor='black')\n",
    "    plt.axvline(x=0, color='r', linestyle='--')\n",
    "    plt.xlabel('Prediction Error (Actual - Predicted)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Prediction Errors')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('error_distribution.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Error vs Predicted plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_pred, results_df['Error'], alpha=0.6)\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.xlabel('Predicted Rating')\n",
    "    plt.ylabel('Prediction Error')\n",
    "    plt.title('Prediction Error vs Predicted Rating')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('error_vs_predicted.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Return results dataframe for further analysis\n",
    "    return results_df\n",
    "\n",
    "#  Save and load the model\n",
    "def save_model(model, filename='movie_rating_model.pkl'):\n",
    "    \"\"\"\n",
    "    Save the trained model to a file\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        print(f\"Model saved successfully to {filename}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def load_model(filename='movie_rating_model.pkl'):\n",
    "    \"\"\"\n",
    "    Load a trained model from a file\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "        print(f\"Model loaded successfully from {filename}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# 13. Main function\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the entire pipeline\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Movie Rating Prediction System\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Ask for file path\n",
    "    file_path = input(\"Enter the path to your movie dataset CSV file (or press Enter to use sample data): \")\n",
    "    if not file_path.strip():\n",
    "        file_path = \"sample_movies.csv\"  # This will trigger the sample data creation\n",
    "    \n",
    "    # 1. Load and explore data\n",
    "    df = load_and_explore_data(file_path)\n",
    "    \n",
    "    # 2. Preprocess data\n",
    "    processed_df = preprocess_data(df)\n",
    "    \n",
    "    # 3. Engineer features\n",
    "    featured_df = engineer_features(processed_df)\n",
    "    \n",
    "    # 4. Prepare for modeling\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test, numerical_cols, categorical_cols = prepare_for_modeling(featured_df)\n",
    "        \n",
    "        # 5. Build and evaluate model\n",
    "        best_model, results = build_and_evaluate_model(X_train, X_test, y_train, y_test, numerical_cols, categorical_cols)\n",
    "        \n",
    "        # 6. Analyze feature importance\n",
    "        feature_importance = analyze_feature_importance(best_model, numerical_cols, categorical_cols)\n",
    "        \n",
    "        # 7. Tune the best model\n",
    "        best_model_name = max(results, key=lambda k: results[k]['R2'])\n",
    "        tuned_model = tune_best_model(X_train, y_train, best_model_name, numerical_cols, categorical_cols)\n",
    "        \n",
    "        # 8. Evaluate the tuned model\n",
    "        tuned_preds = tuned_model.predict(X_test)\n",
    "        tuned_r2 = r2_score(y_test, tuned_preds)\n",
    "        tuned_rmse = np.sqrt(mean_squared_error(y_test, tuned_preds))\n",
    "        \n",
    "        print(f\"\\nTuned Model Performance:\")\n",
    "        print(f\"  RMSE: {tuned_rmse:.4f}\")\n",
    "        print(f\"  R-squared: {tuned_r2:.4f}\")\n",
    "        \n",
    "        # 9. Visualize predictions\n",
    "        results_df = visualize_predictions(tuned_model, X_test, y_test)\n",
    "        \n",
    "        # 10. Save the model\n",
    "        save_model(tuned_model)\n",
    "        \n",
    "        # 11. Run the interactive rating estimator\n",
    "        print(\"\\nStarting interactive rating estimator...\")\n",
    "        try:\n",
    "            create_interactive_rating_estimator(tuned_model, featured_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating GUI: {str(e)}. Using console interface instead.\")\n",
    "            demonstrate_rating_estimator(tuned_model, featured_df)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in the modeling pipeline: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fb5f18-e832-47d9-a785-5b4bdfc9d822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
